{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@interfaced by HAJUN LEE\n",
    "environment using GOOGLE_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.activations as activations\n",
    "import tensorflow.keras.metrics as metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons.optimizers as optimizers\n",
    "import tensorflow_addons.losses as losses\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as k\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, kernels, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               is_bn=True, is_relu=True, n=2):\n",
    "    \"\"\" Custom function for conv2d:\n",
    "        Apply  3*3 convolutions with BN and relu.\n",
    "    \"\"\"\n",
    "    for i in range(1, n + 1):\n",
    "        x = k.layers.Conv2D(filters=kernels, kernel_size=kernel_size,\n",
    "                            padding=padding, strides=strides,\n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "                            kernel_initializer=k.initializers.he_normal(seed=5))(x)\n",
    "        if is_bn:\n",
    "            x = k.layers.BatchNormalization()(x)\n",
    "        if is_relu:\n",
    "            x = k.activations.relu(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet_3Plus(INPUT_SHAPE, OUTPUT_CHANNELS):\n",
    "    filters = [32, 64, 128, 256, 512]\n",
    "\n",
    "    input_layer = k.layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")  # 320*320*3\n",
    "\n",
    "    \"\"\" Encoder\"\"\"\n",
    "    # block 1\n",
    "    e1 = conv_block(input_layer, filters[0])  # 320*320*64\n",
    "\n",
    "    # block 2\n",
    "    e2 = k.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 160*160*64\n",
    "    e2 = conv_block(e2, filters[1])  # 160*160*128\n",
    "\n",
    "    # block 3\n",
    "    e3 = k.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 80*80*128\n",
    "    e3 = conv_block(e3, filters[2])  # 80*80*256\n",
    "\n",
    "    # block 4\n",
    "    e4 = k.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 40*40*256\n",
    "    e4 = conv_block(e4, filters[3])  # 40*40*512\n",
    "\n",
    "    # block 5\n",
    "    # bottleneck layer\n",
    "    e5 = k.layers.MaxPool2D(pool_size=(2, 2))(e4)  # 20*20*512\n",
    "    e5 = conv_block(e5, filters[4])  # 20*20*1024\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    cat_channels = filters[0]\n",
    "    cat_blocks = len(filters)\n",
    "    upsample_channels = cat_blocks * cat_channels\n",
    "\n",
    "    \"\"\" d4 \"\"\"\n",
    "    e1_d4 = k.layers.MaxPool2D(pool_size=(8, 8))(e1)  # 320*320*64  --> 40*40*64\n",
    "    e1_d4 = conv_block(e1_d4, cat_channels, n=1)  # 320*320*64  --> 40*40*64\n",
    "\n",
    "    e2_d4 = k.layers.MaxPool2D(pool_size=(4, 4))(e2)  # 160*160*128 --> 40*40*128\n",
    "    e2_d4 = conv_block(e2_d4, cat_channels, n=1)  # 160*160*128 --> 40*40*64\n",
    "\n",
    "    e3_d4 = k.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 80*80*256  --> 40*40*256\n",
    "    e3_d4 = conv_block(e3_d4, cat_channels, n=1)  # 80*80*256  --> 40*40*64\n",
    "\n",
    "    e4_d4 = conv_block(e4, cat_channels, n=1)  # 40*40*512  --> 40*40*64\n",
    "\n",
    "    e5_d4 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)  # 80*80*256  --> 40*40*256\n",
    "    e5_d4 = conv_block(e5_d4, cat_channels, n=1)  # 20*20*1024  --> 20*20*64\n",
    "\n",
    "    d4 = k.layers.concatenate([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n",
    "    d4 = conv_block(d4, upsample_channels, n=1)  # 40*40*320  --> 40*40*320\n",
    "\n",
    "    \"\"\" d3 \"\"\"\n",
    "    e1_d3 = k.layers.MaxPool2D(pool_size=(4, 4))(e1)  # 320*320*64 --> 80*80*64\n",
    "    e1_d3 = conv_block(e1_d3, cat_channels, n=1)  # 80*80*64 --> 80*80*64\n",
    "\n",
    "    e2_d3 = k.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 160*160*256 --> 80*80*256\n",
    "    e2_d3 = conv_block(e2_d3, cat_channels, n=1)  # 80*80*256 --> 80*80*64\n",
    "\n",
    "    e3_d3 = conv_block(e3, cat_channels, n=1)  # 80*80*512 --> 80*80*64\n",
    "\n",
    "    e4_d3 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)  # 40*40*320 --> 80*80*320\n",
    "    e4_d3 = conv_block(e4_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
    "\n",
    "    e5_d3 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)  # 20*20*320 --> 80*80*320\n",
    "    e5_d3 = conv_block(e5_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
    "\n",
    "    d3 = k.layers.concatenate([e1_d3, e2_d3, e3_d3, e4_d3, e5_d3])\n",
    "    d3 = conv_block(d3, upsample_channels, n=1)  # 80*80*320 --> 80*80*320\n",
    "\n",
    "    \"\"\" d2 \"\"\"\n",
    "    e1_d2 = k.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 320*320*64 --> 160*160*64\n",
    "    e1_d2 = conv_block(e1_d2, cat_channels, n=1)  # 160*160*64 --> 160*160*64\n",
    "\n",
    "    e2_d2 = conv_block(e2, cat_channels, n=1)  # 160*160*256 --> 160*160*64\n",
    "\n",
    "    d3_d2 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d3)  # 80*80*320 --> 160*160*320\n",
    "    d3_d2 = conv_block(d3_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    d4_d2 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d4)  # 40*40*320 --> 160*160*320\n",
    "    d4_d2 = conv_block(d4_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    e5_d2 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)  # 20*20*320 --> 160*160*320\n",
    "    e5_d2 = conv_block(e5_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    d2 = k.layers.concatenate([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n",
    "    d2 = conv_block(d2, upsample_channels, n=1)  # 160*160*320 --> 160*160*320\n",
    "\n",
    "    \"\"\" d1 \"\"\"\n",
    "    e1_d1 = conv_block(e1, cat_channels, n=1)  # 320*320*64 --> 320*320*64\n",
    "\n",
    "    d2_d1 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d2)  # 160*160*320 --> 320*320*320\n",
    "    d2_d1 = conv_block(d2_d1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    d3_d1 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d3)  # 80*80*320 --> 320*320*320\n",
    "    d3_d1 = conv_block(d3_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
    "\n",
    "    d4_d1 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(d4)  # 40*40*320 --> 320*320*320\n",
    "    d4_d1 = conv_block(d4_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
    "\n",
    "    e5_d1 = k.layers.UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)  # 20*20*320 —> 320*320*320\n",
    "    e5_d1 = conv_block(e5_d1, cat_channels, n=1)  # 320*320*320 —> 320*320*64\n",
    "\n",
    "    d1 = k.layers.concatenate([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1, ])\n",
    "    d1 = conv_block(d1, upsample_channels, n=1)  # 320*320*320 —> 320*320*320\n",
    "\n",
    "    # last layer does not have batchnorm and relu\n",
    "    d = conv_block(d1, OUTPUT_CHANNELS, n=1, is_bn=False, is_relu=False)\n",
    "\n",
    "    if OUTPUT_CHANNELS == 1:\n",
    "        output = k.activations.sigmoid(d)\n",
    "    else:\n",
    "        output = k.activations.softmax(d)\n",
    "\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output, name='UNet_3Plus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "x_train = np.load('/content/drive/MyDrive/dataset/x_train.npy')\n",
    "y_train = np.load('/content/drive/MyDrive/dataset/y_train.npy')\n",
    "x_val = np.load('/content/drive/MyDrive/dataset/x_val.npy')\n",
    "y_val = np.load('/content/drive/MyDrive/dataset/y_val.npy')\n",
    "\n",
    "\n",
    "model = UNet_3Plus((256, 256, 1), 1)\n",
    "#model.summary()\n",
    "\n",
    "optim = keras.optimizers.Adam(0.0001)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optim,loss= 'binary_crossentropy', metrics=metrics)\n",
    "\n",
    "model.load_weights('/content/drive/MyDrive/dataset/final_ct2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "#import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cal_base(y_true, y_pred):\n",
    "    y_pred_positive = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_negative = 1 - y_pred_positive\n",
    "\n",
    "    y_positive = K.round(K.clip(y_true, 0, 1))\n",
    "    y_negative = 1 - y_positive\n",
    "\n",
    "    TP = K.sum(y_positive * y_pred_positive)\n",
    "    TN = K.sum(y_negative * y_pred_negative)\n",
    "\n",
    "    FP = K.sum(y_negative * y_pred_positive)\n",
    "    FN = K.sum(y_positive * y_pred_negative)\n",
    "\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PA(y_true, y_pred):\n",
    "    TP, TN, FP, FN = cal_base(y_true, y_pred)\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "    return ACC\n",
    "[]\n",
    "#acc = PA(mask,preds)\n",
    "#print(acc)\n",
    "\n",
    "print(x_val.shape, y_val.shape)\n",
    "PAList = []\n",
    "preds = model.predict(x_val)\n",
    "hh=0\n",
    "for i,pred in enumerate(preds):\n",
    "  #plt.imshow(x_val[i].squeeze(),cmap='gray')\n",
    "  #plt.show()\n",
    "  #plt.imshow(y_val[i].squeeze(),cmap='gray')\n",
    "  #plt.show()\n",
    "  #plt.imshow(pred.squeeze(),cmap='gray')\n",
    "  #plt.show()\n",
    "  #pred = np.reshape(pred,(256,256))\n",
    "  acc= PA(y_val,pred)\n",
    "  acc = acc.numpy()\n",
    "  PAList.append(acc)\n",
    "  \n",
    "#print(PAList)\n",
    "print(\"MPA:%f\" % (sum(PAList) / 27))\n",
    "  #plt.imsave(f'/content/drive/MyDrive/dataset/predict/image'+str(hh+1)+'.png', pred,cmap='gray')\n",
    "  #hh+=1\n",
    "#valid_dataset[24]\n",
    "#image = np.expand_dims(image, axis=0)\n",
    "  #preds = model.predict(image).round()\n",
    "\n",
    "# plt.imshow(image.squeeze(), cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.imshow(image.squeeze(), cmap='gray')\n",
    "# plt.show()\n",
    "# plt.imshow(mask.squeeze(), cmap='gray')\n",
    "# plt.show()\n",
    "# plt.imshow(preds.squeeze(), cmap='gray')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_base(y_true, y_pred):\n",
    "    y_pred_positive = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_negative = 1 - y_pred_positive\n",
    "\n",
    "    y_positive = K.round(K.clip(y_true, 0, 1))\n",
    "    y_negative = 1 - y_positive\n",
    "\n",
    "    TP = K.sum(y_positive * y_pred_positive)\n",
    "    TN = K.sum(y_negative * y_pred_negative)\n",
    "\n",
    "    FP = K.sum(y_negative * y_pred_positive)\n",
    "    FN = K.sum(y_positive * y_pred_negative)\n",
    "\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PA(y_true, y_pred):\n",
    "    TP, TN, FP, FN = cal_base(y_true, y_pred)\n",
    "    ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "    return ACC\n",
    "[]\n",
    "acc = PA(mask,preds)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
