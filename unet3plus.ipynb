{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@interfaced by HAJUN LEE\n",
    "environment using GOOGLE_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.activations as activations\n",
    "import tensorflow.keras.metrics as metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons.optimizers as optimizers\n",
    "import tensorflow_addons.losses as losses\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as k\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, kernels, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               is_bn=True, is_relu=True, n=2):\n",
    "    \"\"\" Custom function for conv2d:\n",
    "        Apply  3*3 convolutions with BN and relu.\n",
    "    \"\"\"\n",
    "    for i in range(1, n + 1):\n",
    "        x = k.layers.Conv2D(filters=kernels, kernel_size=kernel_size,\n",
    "                            padding=padding, strides=strides,\n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "                            kernel_initializer=k.initializers.he_normal(seed=5))(x)\n",
    "        if is_bn:\n",
    "            x = k.layers.BatchNormalization()(x)\n",
    "        if is_relu:\n",
    "            x = k.activations.relu(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet_3Plus(INPUT_SHAPE, OUTPUT_CHANNELS):\n",
    "    filters = [32, 64, 128, 256, 512]\n",
    "\n",
    "    input_layer = k.layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")  # 320*320*3\n",
    "\n",
    "    \"\"\" Encoder\"\"\"\n",
    "    # block 1\n",
    "    e1 = conv_block(input_layer, filters[0])  # 320*320*64\n",
    "\n",
    "    # block 2\n",
    "    e2 = k.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 160*160*64\n",
    "    e2 = conv_block(e2, filters[1])  # 160*160*128\n",
    "\n",
    "    # block 3\n",
    "    e3 = k.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 80*80*128\n",
    "    e3 = conv_block(e3, filters[2])  # 80*80*256\n",
    "\n",
    "    # block 4\n",
    "    e4 = k.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 40*40*256\n",
    "    e4 = conv_block(e4, filters[3])  # 40*40*512\n",
    "\n",
    "    # block 5\n",
    "    # bottleneck layer\n",
    "    e5 = k.layers.MaxPool2D(pool_size=(2, 2))(e4)  # 20*20*512\n",
    "    e5 = conv_block(e5, filters[4])  # 20*20*1024\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    cat_channels = filters[0]\n",
    "    cat_blocks = len(filters)\n",
    "    upsample_channels = cat_blocks * cat_channels\n",
    "\n",
    "    \"\"\" d4 \"\"\"\n",
    "    e1_d4 = k.layers.MaxPool2D(pool_size=(8, 8))(e1)  # 320*320*64  --> 40*40*64\n",
    "    e1_d4 = conv_block(e1_d4, cat_channels, n=1)  # 320*320*64  --> 40*40*64\n",
    "\n",
    "    e2_d4 = k.layers.MaxPool2D(pool_size=(4, 4))(e2)  # 160*160*128 --> 40*40*128\n",
    "    e2_d4 = conv_block(e2_d4, cat_channels, n=1)  # 160*160*128 --> 40*40*64\n",
    "\n",
    "    e3_d4 = k.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 80*80*256  --> 40*40*256\n",
    "    e3_d4 = conv_block(e3_d4, cat_channels, n=1)  # 80*80*256  --> 40*40*64\n",
    "\n",
    "    e4_d4 = conv_block(e4, cat_channels, n=1)  # 40*40*512  --> 40*40*64\n",
    "\n",
    "    e5_d4 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)  # 80*80*256  --> 40*40*256\n",
    "    e5_d4 = conv_block(e5_d4, cat_channels, n=1)  # 20*20*1024  --> 20*20*64\n",
    "\n",
    "    d4 = k.layers.concatenate([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n",
    "    d4 = conv_block(d4, upsample_channels, n=1)  # 40*40*320  --> 40*40*320\n",
    "\n",
    "    \"\"\" d3 \"\"\"\n",
    "    e1_d3 = k.layers.MaxPool2D(pool_size=(4, 4))(e1)  # 320*320*64 --> 80*80*64\n",
    "    e1_d3 = conv_block(e1_d3, cat_channels, n=1)  # 80*80*64 --> 80*80*64\n",
    "\n",
    "    e2_d3 = k.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 160*160*256 --> 80*80*256\n",
    "    e2_d3 = conv_block(e2_d3, cat_channels, n=1)  # 80*80*256 --> 80*80*64\n",
    "\n",
    "    e3_d3 = conv_block(e3, cat_channels, n=1)  # 80*80*512 --> 80*80*64\n",
    "\n",
    "    e4_d3 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)  # 40*40*320 --> 80*80*320\n",
    "    e4_d3 = conv_block(e4_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
    "\n",
    "    e5_d3 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)  # 20*20*320 --> 80*80*320\n",
    "    e5_d3 = conv_block(e5_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
    "\n",
    "    d3 = k.layers.concatenate([e1_d3, e2_d3, e3_d3, e4_d3, e5_d3])\n",
    "    d3 = conv_block(d3, upsample_channels, n=1)  # 80*80*320 --> 80*80*320\n",
    "\n",
    "    \"\"\" d2 \"\"\"\n",
    "    e1_d2 = k.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 320*320*64 --> 160*160*64\n",
    "    e1_d2 = conv_block(e1_d2, cat_channels, n=1)  # 160*160*64 --> 160*160*64\n",
    "\n",
    "    e2_d2 = conv_block(e2, cat_channels, n=1)  # 160*160*256 --> 160*160*64\n",
    "\n",
    "    d3_d2 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d3)  # 80*80*320 --> 160*160*320\n",
    "    d3_d2 = conv_block(d3_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    d4_d2 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d4)  # 40*40*320 --> 160*160*320\n",
    "    d4_d2 = conv_block(d4_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    e5_d2 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)  # 20*20*320 --> 160*160*320\n",
    "    e5_d2 = conv_block(e5_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    d2 = k.layers.concatenate([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n",
    "    d2 = conv_block(d2, upsample_channels, n=1)  # 160*160*320 --> 160*160*320\n",
    "\n",
    "    \"\"\" d1 \"\"\"\n",
    "    e1_d1 = conv_block(e1, cat_channels, n=1)  # 320*320*64 --> 320*320*64\n",
    "\n",
    "    d2_d1 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d2)  # 160*160*320 --> 320*320*320\n",
    "    d2_d1 = conv_block(d2_d1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
    "\n",
    "    d3_d1 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d3)  # 80*80*320 --> 320*320*320\n",
    "    d3_d1 = conv_block(d3_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
    "\n",
    "    d4_d1 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(d4)  # 40*40*320 --> 320*320*320\n",
    "    d4_d1 = conv_block(d4_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
    "\n",
    "    e5_d1 = k.layers.UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)  # 20*20*320 —> 320*320*320\n",
    "    e5_d1 = conv_block(e5_d1, cat_channels, n=1)  # 320*320*320 —> 320*320*64\n",
    "\n",
    "    d1 = k.layers.concatenate([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1, ])\n",
    "    d1 = conv_block(d1, upsample_channels, n=1)  # 320*320*320 —> 320*320*320\n",
    "\n",
    "    # last layer does not have batchnorm and relu\n",
    "    d = conv_block(d1, OUTPUT_CHANNELS, n=1, is_bn=False, is_relu=False)\n",
    "\n",
    "    if OUTPUT_CHANNELS == 1:\n",
    "        output = k.activations.sigmoid(d)\n",
    "    else:\n",
    "        output = k.activations.softmax(d)\n",
    "\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output, name='UNet_3Plus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/content/drive/MyDrive/BUSI'\n",
    "x_train_dir = os.path.join(DATA_DIR, 'train') #train 오리지널이미지\n",
    "y_train_dir = os.path.join(DATA_DIR, 'train_annot')  #train 마스크 이미지\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'val_annot')\n",
    "\n",
    "class Dataset:\n",
    "\n",
    "    CLASSES = ['lesion']\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            images_dir,\n",
    "            masks_dir,\n",
    "            classes=None,\n",
    "            augmentation=None,\n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "        mask = cv2.imread(self.masks_fps[i], cv2.IMREAD_GRAYSCALE).astype(np.float32)  # [H, W]\n",
    "        mask = np.expand_dims(mask, -1)  # [H, W, 1]\n",
    "\n",
    "\n",
    "        #image /= 255.0\n",
    "        mask /= 255.0\n",
    "        mask[mask > 1.0] = 1.0\n",
    "\n",
    "        # # extract certain classes from mask (e.g. cars)\n",
    "        # masks = [(mask == v) for v in self.class_values]\n",
    "        # mask = np.stack(masks, axis=-1).astype('float')\n",
    "\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "import keras\n",
    "class Dataloder(keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "\n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, batch_size=32, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        # transpose list of lists\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)\n",
    "\n",
    "#Lets look at data we have\n",
    "dataset = Dataset(x_train_dir, y_train_dir, classes=['lesion'])\n",
    "image, mask = dataset[8] # get some sample\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "CLASSES = ['lesion']\n",
    "LR = 0.0001\n",
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "#########모델정의\n",
    " \n",
    "model = UNet_3Plus((256, 256, 3), 1)\n",
    "model.summary()\n",
    "\n",
    "optim = keras.optimizers.Adam(0.0001)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optim,loss= 'binary_crossentropy', metrics=metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    x_train_dir,\n",
    "    y_train_dir,\n",
    "    classes=['lesion'],\n",
    ")\n",
    "\n",
    "# Dataset for validation images\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir,\n",
    "    y_valid_dir,\n",
    "    classes=['lesion'],\n",
    ")\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = Dataloder(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model.load_weights('/content/drive/MyDrive/BUSI/final.pth')\n",
    "\n",
    "# check shapes for errors\n",
    "assert train_dataloader[0][0].shape == (BATCH_SIZE, 256, 256, 3)\n",
    "assert train_dataloader[0][1].shape == (BATCH_SIZE, 256, 256, 1)\n",
    "\n",
    "assert valid_dataloader[0][0].shape == (BATCH_SIZE, 256, 256, 3)\n",
    "assert valid_dataloader[0][1].shape == (BATCH_SIZE, 256, 256, 1)\n",
    "\n",
    "\n",
    "##pred 뽑을때 잠궈야함************************\n",
    "callbacks = [\n",
    "    # keras.callbacks.ModelCheckpoint('./best.hdf5', save_weights_only=True, save_best_only=True),\n",
    "    keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/BUSI/final2.pth', monitor='val_loss', save_best_only=True),\n",
    "    # keras.callbacks.ReduceLROnPlateau(),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "]\n",
    "# train model\n",
    "history = model.fit_generator(\n",
    "    train_dataloader,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=valid_dataloader,\n",
    "    validation_steps=len(valid_dataloader),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
